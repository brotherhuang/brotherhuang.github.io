<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<title>Haibin Huang</title>
	<meta name="description" content="Haibin Huang's Homepage">
	<meta name="author" content="Haibin Huang">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<link href="./style_files/bootstrap.min.css" type="text/css" rel="stylesheet">
	<link href="./style_files/custom.css" type="text/css" rel="stylesheet">

</head>

<!-- Body. -->

<body>

	<div class="container">
		<h1>Haibin Huang</h1>
	</div>

	<div class="container anchor" id="Top">
		<div class="row row-offcanvas row-offcanvas-right">
			<div class="col-lg-3 col-md-3 col-sm-3">
				<img width="250px" src="images/me_kwai.png" class="img-responsive" style="border:0px solid #000000"
					alt="Haibin Huang">
			</div>
			<div class="col-lg-6 col-md-6 col-sm-6">
				<big>
					<p>Research Scientist, Generative AI</p>
					<p><a href="https://www.bytedance.com/en"> ByteDance </a></p>
					<p>1199 Coleman Ave, San Jose, CA 95110 </p>
					<p>jackiehuanghaibin <b> at </b> gmail <b> dot</b> com </p>
					<p><a href="./files/resume_2024.pdf" class="button">CV</a> | <a
							href="https://scholar.google.com/citations?user=YDl1M80AAAAJ&hl=en"> Google Scholar </a> |
						<a href="https://github.com/brotherhuang"> GitHub </a>
					</p>
				</big><br>
			</div>
		</div>
		<br>
	</div>

	<div class="container section-anchor" id="Bio">
		<h2>About Me</h2>
		<p>
		<h3> I recently joined <a title="https://www.bytedance.com/en" href="https://www.bytedance.com/en"
				class="style">ByteDance</a> as a Generative AI Researcher. Prior to this role, I
			dedicated four years to <a title="https://www.kuaishou.com/en" href="https://www.kuaishou.com/en"
				class="style">Kuaishou Technology</a> as Staff Research Scientist and spent two years as a
			Research Scientist at <a title="https://en.megvii.com/megvii_research"
				href="https://en.megvii.com/megvii_research" class="style">Megvii Research</a>. I earned my Ph.D. in
			Computer Science from the University of
			Massachusetts Amherst, where I was a part of the <a title="http://graphics.cs.umass.edu/"
				href="http://graphics.cs.umass.edu/" class="style">Computer Graphics Research Group</a> under the
			guidance of
			<a title="http://people.cs.umass.edu/~kalo/" href="http://people.cs.umass.edu/~kalo/">Prof. Evangelos
				Kalogerakis</a> and
			<a title="http://people.cs.umass.edu/~ruiwang/" href="http://people.cs.umass.edu/~ruiwang/">Prof. Rui
				Wang</a>. Before joining UMass Amherst, I obtained my bachelor's and master's degrees in <a
				title="http://www.math.zju.edu.cn/mathen/" href="http://www.math.zju.edu.cn/mathen/">Department of
				Mathematics</a><a title="http://www.zju.edu.cn/english/" href="http://www.zju.edu.cn/english/"> ,
				Zhejiang University</a>.
			</p>
		</h3>
		<p>
		<h3> My research is dedicated to the analysis and creation of visual content through the integration of computer
			vision, computer graphics, and machine learning. I aim to devise techniques that simplify the creation and
			manipulation of digital content, thereby making these processes more user-friendly and accessible.
			</p>
		</h3>
		<p>
		<h3>
			<font COLOR="FF0000">[2025/04 Update] </font> Our team is hiring full-time research scientists and interns
			specializing in generative AI, with a focus on video synthesis and editing. Please feel free to drop me an
			email if you are interested.
		</h3>
		</p>
	</div>

	<div class="container section-anchor" id="Work">
		<h2>Work Experience</h2>
		<div class="publication">
			<div class="thumb"><a href="https://www.bytedance.com/en"><img src="images/logo_ByteDance.png"></a>&nbsp;
			</div>
			<div class="title">Researcher of Generative AI </a></div>
			<div class="time">
				<em> Mar 2024 ~ Present </em>
			</div>
			<br>
		</div>
		<div class="publication">
			<div class="thumb"><a href="https://www.kuaishou.com/en"><img src="images/kwai.png"></a>&nbsp;
			</div>
			<div class="title">Senior Staff Research Scientist</a></div>
			<div class="time">
				<em> Nov 2019 ~ Mar 2024 </em>
			</div>
			<br>
		</div>

		<div class="publication">
			<div class="thumb"><a href="https://en.megvii.com/megvii_research"><img
						src="images/megvii_face.png"></a>&nbsp;
			</div>
			<div class="title">Research Scientist</a></div>
			<div class="time">
				<em> October 2017 ~ Nov 2019 </em>
			</div>
			<br>
		</div>
	</div>
	<!--
<h2>Other Positions</h2>
	<div class="work">
		<div class="thumb"><img src="images/autodesk.jpg"</a>&nbsp;</div>
		<div class="title"><h4>Research intern, Computational Science Research Group</h4></div>
		<div class="time"> 
		February 2017 ~ August 2017
		</div>
	</div>
	<div class="work">
		<div class="thumb"><img src="images/adobe.jpg"</a>&nbsp;</div>
		<div class="title"><h4>Research intern, Imagination Lab, Adobe Research</h4></div>
		<div class="time"> 
		May 2015 ~ January 2016
		</div>
	</div>
 </div>
 -->

	<div class="container section-anchor" id="Research">



		<!--<div class="container section-anchor" id="Preprints ">
		<h2>Preprints</h2>
	
		
		<div class="publication">
			<div class="thumb"><a href="https://ishape.github.io/"><img src="./publications/ishape/ishape.png"></a>&nbsp;</div>
			<div class="title"><a href="https://ishape.github.io/">	iShape: A First Step Towards Irregular Shape Instance Segmentation </a></div>
			<div class="authors">
				Lei Yang, Yan Zi Wei, Wei Sun, Yisheng He, Zhenhang Huang, <strong> Haibin Huang</strong>, Haoqiang Fan
			</div>
			<div class="cite">
			[ <a href="https://ishape.github.io/">Project page</a> ]
			</div>
			<br>
		</div>
		
			
		
			<div class="publication">
				<div class="thumb"><a href="https://arxiv.org/abs/1905.02882"><img src="./publications/frame_lstm/conv_lstm.png"></a>&nbsp;</div>
				<div class="title"><a href="https://arxiv.org/abs/1905.02882">	Frame-Recurrent Video Inpainting by Robust Optical Flow Inference	</a></div>
				<div class="authors">
						Yifan Ding, Chuan Wang, <strong> Haibin Huang</strong>, Jiaming Liu, Jue Wang, Liqiang Wang
				</div>
				<div class="venue">
				<em> Arxiv 2019</em>
				</div>
				<div class="cite">
				[ <a href="https://arxiv.org/abs/1905.02882">Project page</a> ] [ <a href="https://arxiv.org/pdf/1905.02882.pdf"> Paper </a>]
				</div>
				<br>
			</div>
		End of project 
	-->



		<h2>Publications</h2>
		<!--  TPAMI 2025   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/pftg/pftg.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Physically Based Facial Texture Generation in
					the Wild
				</a></div>
			<div class="authors">
				Chi Wang, Junming Huang, Rong Zhang, Qi Wang, Haotian Yang, Pengfei Wan, <strong> Haibin Huang</strong>,
				Chongyang Ma,Weiwei Xu
			</div>
			<div class="venue">
				<em>TPAMI 2025</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  TVCG 2025   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/motion_craft/motion_craft.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> MotionCrafter: Plug-and-play Motion Guidance
					for Diffusion Models</a></div>
			<div class="authors">
				Yuxin Zhang, Weiming Dong, Member, Fan Tang, Nisha Huang, <strong> Haibin Huang</strong>, Chongyang Ma,
				Pengfei Wan, Tong-Yee Lee, Changsheng Xu
			</div>
			<div class="venue">
				<em>TVCG 2025</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIGGRAPH 2025   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/ip_prompter/ip.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> IP-Prompter: Training-Free Theme-Specific
					Image Generation via Dynamic Visual Prompting</a></div>
			<div class="authors">
				Yuxin Zhang, Minyan Luo, Weiming Dong, Xiao Yang, <strong> Haibin Huang</strong>, Chongyang Ma, Oliver
				Deussen, Tong-Yee
				Lee, Changsheng Xu
			</div>
			<div class="venue">
				<em>ACM SIGGRAPH 2025</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!-- CSCWD 2025   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/creative-agent/ca.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Creative-Agent: A Creative Prototype
					Generation System Driven by Objectives and Key Results</a></div>
			<div class="authors">
				Yi Zheng, Chongyang Ma, Kanle Shi, <strong> Haibin Huang</strong>, Jingwei Chen
			</div>
			<div class="venue">
				<em>CSCWD 2025</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->



		<!--  NeurIPS 2024   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/DeTeCtive/detective.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> DeTeCtive: Detecting AI-generated Text via
					Multi-Level Contrastive Learning</a></div>
			<div class="authors">
				Xun Guo, Yongxin He, Shan Zhang, Ting Zhang, Wanquan Feng, <strong> Haibin Huang</strong>, Chongyang Ma
			</div>
			<div class="venue">
				<em>NeurIPS 2024</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--   NeurIPS 2024   -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/yola/yola.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/">You Only Look Around: Learning
					Illumination-Invariant Feature for Low-light Object Detection</a></div>
			<div class="authors">
				Mingbo Hong, Shen Cheng, <strong> Haibin Huang</strong>, Haoqiang Fan, Shuaicheng Liu
			</div>
			<div class="venue">
				<em>NeurIPS 2024</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIGASIA 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/unihair/unihair.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/">Towards Unified 3D Hair Reconstruction from
					Single-View Portraits</a></div>
			<div class="authors">
				Yujian Zheng, Yuda Qiu, Leyang Jin, Chongyang Ma, <strong> Haibin Huang</strong>, Di Zhang, Pengfei
				Wang, Xiaoguang Han
			</div>
			<div class="venue">
				<em>SIGGRAPHASIA 2024</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  ECCV 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://sisidai.github.io/InterFusion/"><img
						src="./publications/interfusion/InterFusion.png "></a>&nbsp;</div>
			<div class="title"><a href="https://sisidai.github.io/InterFusion/">InterFusion: Text-Driven Generation of
					3D Human-Object Interaction</a></div>
			<div class="authors">
				Sisi Dai, Wenhao Li, Haowen Sun, <strong> Haibin Huang</strong>, Chongyang Ma, Hui Huang, Kai Xu,
				Ruizhen Hu
			</div>
			<div class="venue">
				<em>ECCV 2024</em>
			</div>
			<div class="cite">
				[ <a href="https://sisidai.github.io/InterFusion/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2403.15612">
					Paper </a>] [ <a href="https://sisidai.github.io/InterFusion/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIG 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://direct-a-video.github.io/"><img
						src="./publications/dirct_a_video/director_a_video.png "></a>&nbsp;</div>
			<div class="title"><a href="https://direct-a-video.github.io/">Direct-a-Video: Customized Video Generation
					with User-Directed Camera Movement and Object Motion</a></div>
			<div class="authors">
				Shiyuan Yang, Liang Hou, <strong> Haibin Huang</strong>, Chongyang Ma, Pengfei Wan, Di Zhang, Xiaodong
				Chen, Jing Liao
			</div>
			<div class="venue">
				<em>SIGGRAPH 2024 (Conference)</em>
			</div>
			<div class="cite">
				[ <a href="https://direct-a-video.github.io/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2402.03162">
					Paper </a>] [ <a href="https://direct-a-video.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIG 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://i2v-adapter.github.io/"><img
						src="./publications/i2v_adaptor/i2v_adaptor.jpeg "></a>&nbsp;</div>
			<div class="title"><a href="https://i2v-adapter.github.io/">I2V-Adapter: A General Image-to-Video Adapter
					for Diffusion Models</a></div>
			<div class="authors">
				Xun Guo, Mingwu Zheng, Liang Hou, Yuan Gao, Yufan Deng, Pengfei Wan, Di Zhang, Yufan Liu, Weiming Hu,
				Zhengjun Zha, <strong> Haibin Huang</strong>, Chongyang Ma
			</div>
			<div class="venue">
				<em>SIGGRAPH 2024 (Conference)</em>
			</div>
			<div class="cite">
				[ <a href="https://i2v-adapter.github.io/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2312.16693">
					Paper </a>] [ <a href="https://i2v-adapter.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/inter_trans/inter_tran.jpeg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/">Spatial and Surface Correspondence Field for
					Interaction Transfer</a></div>
			<div class="authors">
				Zeyu Huang, Honghao Xu, <strong> Haibin Huang</strong>, Chongyang Ma, Hui Huang, Ruizhen Hu
			</div>
			<div class="venue">
				<em> SIGGRAPH 2024 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<div class="publication">
			<div class="thumb"><a href="https://vrmm-paper.github.io/"><img
						src="./publications/vrmm/vrmm.jpeg"></a>&nbsp;</div>
			<div class="title"><a href="https://vrmm-paper.github.io/">VRMM: A Volumetric Relightable Morphable Head
					Model</a></div>
			<div class="authors">
				Haotian Yang, Mingwu Zheng, Chongyang Ma, Yu-Kun Lai, Pengfei Wan, <strong> Haibin Huang</strong>
			</div>
			<div class="venue">
				<em> SIGGRAPH 2024 (Conference)</em>
			</div>
			<div class="cite">
				[ <a href="https://vrmm-paper.github.io/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2402.04101">
					Paper </a>] [ <a href="https://vrmm-paper.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/lgtm/LGTM.jpeg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/">LGTM: Local-to-Global Text-Driven Human Motion
					Diffusion Model </a></div>
			<div class="authors">
				Haowen Sun, Ruikun Zheng, <strong> Haibin Huang</strong>, Chongyang Ma, Hui Huang, Ruizhen Hu
			</div>
			<div class="venue">
				<em> SIGGRAPH 2024 (Conference)</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>] [ <a href="https://brotherhuang.github.io/">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  TNNLS 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io"><img
						src="./publications/diffstyler/diffstyler.png "></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io"> DiffStyler: Controllable Dual Diffusion for
					Text-Driven Image Stylization </a></div>
			<div class="authors">
				Nisha Huang, Yuxin Zhang, Fan Tang, Chongyang Ma, <strong> Haibin Huang</strong>, Yong Zhang, Weiming
				Dong, Changsheng Xu
			</div>
			<div class="venue">
				<em> TNNLS 2024 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io">Project page</a> ] [ <a
					href="https://brotherhuang.github.io">
					Paper </a>] [ <a href="https://brotherhuang.github.io">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  CVM 2024  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io"><img
						src="./publications/freestyler/freestyler.png "></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io"> FreeStyler: A Free-Form Stylization Method via
					Multimodal Vector Quantization </a></div>
			<div class="authors">
				Wuqin Liu, Minxuan Lin, <strong> Haibin Huang</strong>, Chongyang Ma, Weiming Dong
			</div>
			<div class="venue">
				<em> CVM 2024 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io">Project page</a> ] [ <a
					href="https://brotherhuang.github.io">
					Paper </a>] [ <a href="https://brotherhuang.github.io">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  PG 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://mmfs-paper.github.io/"><img
						src="./publications/mmfs/mmfs.jpg "></a>&nbsp;
			</div>
			<div class="title"><a href="https://mmfs-paper.github.io/"> Multi-Modal Face Stylization with a
					Generative
					Prior </a></div>
			<div class="authors">
				Mengtian Li, Yi Dong, Minxuan Lin, <strong> Haibin Huang</strong>, Pengfei Wan, Chongyang Ma
			</div>
			<div class="venue">
				<em> PG 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://mmfs-paper.github.io/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2305.18009">
					Paper </a>] [ <a href="https://github.com/mmfs-paper/MMFS">
					Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  SIGGRAPHASIA 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/prospct/prospec.png "></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> ProSpect: Prompt Spectrum of Staged
					Diffusion
					Models for Visual Attribute-aware Image Generation </a></div>
			<div class="authors">
				Yuxin Zhang, Weiming Dong, Fan Tang, Nisha Huang, <strong> Haibin Huang</strong>, Chongyang Ma, Tong-Yee
				Lee, Oliver
				Deussen, Changsheng Xu
			</div>
			<div class="venue">
				<em> SIGGRAPHASIA 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIGGRAPHASIA 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://travatar-paper.github.io/"><img
						src="./publications/relight/relight.png "></a>&nbsp;</div>
			<div class="title"><a href="https://travatar-paper.github.io/"> Towards Practical Capture of
					High-Fidelity
					Relightable Avatars </a></div>
			<div class="authors">
				Haotian Yang, Mingwu Zheng, Wanquan Feng, <strong> Haibin Huang</strong>, Yu-Kun Lai, Pengfei Wan,
				Zhongyuan Wang,
				Chongyang Ma
			</div>
			<div class="venue">
				<em> SIGGRAPHASIA 2023 (Conference)</em>
			</div>
			<div class="cite">
				[ <a href="https://travatar-paper.github.io/">Project page</a> ] [ <a
					href="https://arxiv.org/abs/2309.04247"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  ICCV 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img src="./publications/of/of.png "></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Explicit Motion Disentangling for
					Efficient
					Optical Flow Estimation </a></div>
			<div class="authors">
				Changxing Deng, Ao Luo, <strong> Haibin Huang</strong>, Shaodan Ma, Jiangyu Liu,Shuaicheng Liu
			</div>
			<div class="venue">
				<em> ICCV 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SGP 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/NeuralKeypoint/NeuralKeypoint.png "></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> 3D Keypoint Estimation using Implicit
					Representation Learning </a></div>
			<div class="authors">
				Xiangyu Zhu, Dong Du, <strong> Haibin Huang</strong>, Chongyang Ma, Xiaoguang Han
			</div>
			<div class="venue">
				<em> SGP 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  TOG 2023  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/unified_style/unified.png "></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> A Unified Arbitrary Style Transfer
					Framework
					via Adaptive Contrastive Learning </a></div>
			<div class="authors">
				Yuxin Zhang, Fan Tang, Weiming Dong, <strong> Haibin Huang</strong>, Chongyang Ma, Tong-Yee Lee,
				Changsheng Xu
			</div>
			<div class="venue">
				<em> TOG 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  CVPR 2023 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/hair_step/hair_step.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> HairStep: Transfer Synthetic to Real Using
					Strand and Depth Maps for Single-View 3D Hair Modeling </a></div>
			<div class="authors">
				Yujian Zheng, Zirong Jin, Moran Li, <strong> Haibin Huang</strong>, Chongyang Ma, Shuguang Cui,
				Xiaoguang Han
			</div>
			<div class="venue">
				<em> CVPR 2023 (Highlight)</em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  CVPR 2023 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/semi_motion/semi_motion.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Semi-Weakly Supervised Object Kinematic
					Motion
					Prediction </a></div>
			<div class="authors">
				Gengxin Liu, Qian Sun, <strong> Haibin Huang</strong>, Chongyang Ma, Yulan Guo, Li Yi, Hui Huang,
				Ruizhen Hu
			</div>
			<div class="venue">
				<em> CVPR 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  CVPR 2023 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/invert/invert.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Inversion-Based Style Transfer with
					Diffusion
					Models </a></div>
			<div class="authors">
				Yuxin Zhang, Nisha Huang, Fan Tang, <strong> Haibin Huang</strong>, Chongyang Ma, Weiming Dong,
				Changsheng Xu
			</div>
			<div class="venue">
				<em> CVPR 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  ICLR 2023 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/plse/plse.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Self-Supervised Category-Level Articulated
					Object Pose Estimation with Part-Level SE(3) Equivariance </a></div>
			<div class="authors">
				Xueyi Liu, Ji Zhang, Ruizhen Hu, <strong> Haibin Huang</strong>, He Wang, Li Yi
			</div>
			<div class="venue">
				<em> ICLR 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  CVM 2023 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/emm/EMM.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Emotion-Aware Music Driven Movie Montage
				</a>
			</div>
			<div class="authors">
				Wuqin Liu, Minxuan Lin, <strong> Haibin Huang</strong>, Chongyang Ma,Yu Song, Weiming Dong, Changsheng
				Xu
			</div>
			<div class="venue">
				<em> CVM 2023 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  PG2022 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2112.02494"><img
						src="./publications/ind_face/ind_face.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2112.02494"> Implicit Neural Deformation for
					Multi-View
					Face Reconstruction </a></div>
			<div class="authors">
				Moran Li, <strong> Haibin Huang</strong>, Yi Zheng, Mengtian Li, Nong Sang, Chongyang Ma
			</div>
			<div class="venue">
				<em> PG 2022 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2112.02494">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2112.02494.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  IMWUT 2022 -->
		<div class="publication">
			<div class="thumb"><a href="https://yiqinzhao.me/project/litar/"><img
						src="./publications/litar/litar.png"></a>&nbsp;</div>
			<div class="title"><a href="https://yiqinzhao.me/project/litar/"> LitAR: Visually Coherent Lighting for
					Mobile Augmented Reality</a></div>
			<div class="authors">
				Yiqin Zhao, Chongyang Ma, <strong> Haibin Huang</strong>, Tian Guo
			</div>
			<div class="venue">
				<em> IMWUT </em>
			</div>
			<div class="cite">
				[ <a href="https://yiqinzhao.me/project/litar/">Project page</a> ] [ <a
					href="https://yiqinzhao.me/assets/img/project/litar/litar_imwut22.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  ECCV 2022 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2103.14373"><img
						src="./publications/d2c/d2c.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://arxiv.org/abs/2103.14373"> D2C-SR: A Divergence to Convergence
					Approach
					for Image Super-Resolution </a></div>
			<div class="authors">
				Youwei Li, <strong> Haibin Huang</strong>, Lanpeng Jia, Haoqiang Fan, Shuaicheng Liu
			</div>
			<div class="venue">
				<em> ECCV 2022</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2103.14373">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2103.14373.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  SIGGRAPH 2022  -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/cast/cast.png "></a>&nbsp;
			</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Domain Enhanced Arbitrary Image Style
					Transfer
					via Contrastive Learning </a></div>
			<div class="authors">
				Yuxin Zhang, Fan Tang, Weiming Dong, <strong> Haibin Huang</strong>, Chongyang Ma, Tong-Yee Lee,
				Changsheng Xu
			</div>
			<div class="venue">
				<em> SIGGRAPH 2022 (Conference) </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  CVPR 2022  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2202.07508"><img
						src="./publications/dcsr/dcsr.jpg "></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2202.07508"> Deep Constrained Least Squares for Blind
					Image Super-Resolution </a></div>
			<div class="authors">
				Ziwei Luo, <strong> Haibin Huang</strong>, Lei Yu, Youwei Li, Haoqiang Fan, Shuaicheng Liu
			</div>
			<div class="venue">
				<em> CVPR 2022 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2202.07508">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2202.07508.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  TVCG  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2107.04291"><img
						src="./publications/bfps/bfps.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://arxiv.org/abs/2107.04291"> Task-Aware Sampling Layer for Point-Wise
					Analysis </a></div>
			<div class="authors">
				Yiqun Lin, Lichang Chen, <strong> Haibin Huang</strong>, Chongyang Ma, Xiaoguang Han, Shuguang Cui
			</div>
			<div class="venue">
				<em> TVCG 2022 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2107.04291">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2107.04291.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  CVMJ  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2202.08583"><img
						src="./publications/sfm/sfm.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://arxiv.org/abs/2202.08583"> Point cloud completion on structured
					feature
					map with feedback network </a></div>
			<div class="authors">
				Zejia Su, <strong> Haibin Huang</strong>, Chongyang Ma, Hui Huang, Ruizhen Hu
			</div>
			<div class="venue">
				<em> CVMJ 2022 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2202.08583">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2202.08583.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  PG 2021 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/upright/upright.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> UprightRL: Upright Orientation Estimation
					of
					3D Shapes via Reinforcement Learning </a></div>
			<div class="authors">
				Luanmin Chen, Juzhan Xu, Chuan Wang, <strong> Haibin Huang</strong>, Hui Huang, Ruizhen Hu
			</div>
			<div class="venue">
				<em> PG 2021 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  ICCV 2021 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2105.10620"><img
						src="./publications/hpnet/hpnet.jpeg"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2105.10620"> HPNet: Deep Primitive Segmentation Using
					Hybrid Representations </a></div>
			<div class="authors">
				Siming Yan, Zhenpei Yang, Chongyang Ma, <strong> Haibin Huang</strong>, Etienne Vouga, Qixing Huang
			</div>
			<div class="venue">
				<em> ICCV 2021 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2105.10620">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2105.10620.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->



		<!--  ICCV 2021 -->
		<div class="publication">
			<div class="thumb"><a href="https://brotherhuang.github.io/"><img
						src="./publications/scene/scene.png"></a>&nbsp;</div>
			<div class="title"><a href="https://brotherhuang.github.io/"> Scene Synthesis via Uncertainty-Driven
					Attribute Synchronization </a></div>
			<div class="authors">
				Haitao Yang, Zaiwei Zhang, Siming Yan, <strong> Haibin Huang</strong>, Chongyang Ma, Yi Zheng,
				Chandrajit Bajaj,
				Qixing
				Huang
			</div>
			<div class="venue">
				<em> ICCV 2021 </em>
			</div>
			<div class="cite">
				[ <a href="https://brotherhuang.github.io/">Project page</a> ] [ <a
					href="https://brotherhuang.github.io/">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->




		<!--  CVPR 2021  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2103.02242"><img
						src="./publications/ffb6d/ffb6d.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2103.02242"> FFB6D: A Full Flow Bidirectional Fusion
					Network for 6D Pose Estimation </a></div>
			<div class="authors">
				Yisheng He, <strong> Haibin Huang</strong>, Haoqiang Fan, Qifeng Chen, Jian Sun
			</div>
			<div class="venue">
				<em> CVPR 2021 (Oral presentation)</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2103.02242">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2103.02242.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  CVPR 2021  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2012.15028"><img
						src="./publications/nbnet/nbnet.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2012.15028"> NBNet: Noise Basis Learning for Image
					Denoising with Subspace Projection </a></div>
			<div class="authors">
				Shen Cheng, Yuzhi Wang, <strong> Haibin Huang</strong>, Donghao Liu, Haoqiang Fan, Shuaicheng Liu
			</div>
			<div class="venue">
				<em> CVPR 2021</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2012.15028">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2012.15028.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  AAAI 2021  -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2009.08003"><img
						src="./publications/video_style/video_style.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2009.08003"> Arbitrary Video Style Transfer via
					Multi-Channel Correlation </a></div>
			<div class="authors">
				Yingying Deng, Fan Tang, Weiming Dong, <strong> Haibin Huang</strong>, Chongyang Ma, Changsheng Xu
			</div>
			<div class="venue">
				<em> AAAI 2021</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2009.08003">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2009.08003.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  CORL 2020  -->
		<div class="publication">
			<div class="thumb"><a href="https://tonghehehe.com/lates"><img
						src="./publications/lates/lates_demo.png"></a>&nbsp;</div>
			<div class="title"><a href="https://tonghehehe.com/lates"> SAM: Squeeze-and-Mimic Networks for
					Conditional
					Visual Driving Policy Learning </a></div>
			<div class="authors">
				Albert Zhao, Tong He, Yitao Liang, <strong> Haibin Huang</strong>, Guy Van den Broeck, Stefano Soatto
			</div>
			<div class="venue">
				<em> CORL 2020 </em>
			</div>
			<div class="cite">
				[ <a href="https://tonghehehe.com/lates">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1912.02973.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  ECCV 2020 -->
		<div class="publication">
			<div class="thumb"><a href="https://scholar.google.com/citations?user=YDl1M80AAAAJ&hl=en"><img
						src="./publications/superiq/superiq.png"></a>&nbsp;</div>
			<div class="title"><a href="https://scholar.google.com/citations?user=YDl1M80AAAAJ&hl=en"> Practical
					Deep
					Raw Image Denoising on Mobile Devices </a></div>
			<div class="authors">
				Yuzhi Wang, <strong> Haibin Huang</strong>, Qin Xu, Jiaming Liu, Yiqun Liu, Jue Wang
			</div>
			<div class="venue">
				<em> ECCV 2020 (Spotlight presentation) </em>
			</div>
			<div class="cite">
				[ <a href="">Project page</a> ] [ <a
					href="https://scholar.google.com/citations?user=YDl1M80AAAAJ&hl=en">
					Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->
		<!--  CVPR 2020 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/2002.10701"><img
						src="./publications/fpconv/fpconv.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/2002.10701"> FPConv: Learning Local Flattening for
					Point
					Convolution </a></div>
			<div class="authors">
				Yiqun Lin, Zizheng Yan, <strong> Haibin Huang</strong>, Dong Du, Ligang Liu, Shuguang Cui, Xiaoguang Han
			</div>
			<div class="venue">
				<em> CVPR 2020 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/2002.10701">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/2002.10701.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->
		<!--  CVPR 2020 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1911.04231"><img
						src="./publications/pvn3d/pvn3d.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/1911.04231"> PVN3D: A Deep Point-wise 3D Keypoints
					Voting
					Network for 6DoF Pose Estimation </a></div>
			<div class="authors">
				Yisheng He, Wei Sun, <strong> Haibin Huang</strong>, Jianran Liu, Haoqiang Fan, Jian Sun
			</div>
			<div class="venue">
				<em> CVPR 2020 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1911.04231">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1911.04231.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  AAAI 2020 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1904.03485"><img
						src="./publications/awgn_denoiser/denoise.png"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/1904.03485"> When AWGN-based Denoiser Meets Real
					Noises
				</a></div>
			<div class="authors">
				Yuqian Zhou, Jianbo Jiao, <strong> Haibin Huang</strong>, Yang Wang, Jue Wang, Honghui Shi, Thomas Huang
			</div>
			<div class="venue">
				<em> AAAI 2020</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1904.03485">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1904.03485.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!--  ICCV 2019 -->
		<div class="publication">
			<div class="thumb"><a href=""><img src="./publications/matting/matting.png"></a>&nbsp;</div>
			<div class="title"><a href=""> Disentangled Image Matting </a></div>
			<div class="authors">
				Shaofan Cai, Xiaoshuai Zhang, Haoqiang Fan, <strong> Haibin Huang</strong>, Jiangyu Liu, Jiaming Liu,
				Jiaying Liu, Jue
				Wang, Jian Sun
			</div>
			<div class="venue">
				<em> ICCV 2019</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1909.04686">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1909.04686.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--  ICCV 2019 -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1908.01977"><img
						src="./publications/skin/skin.png"></a>&nbsp;
			</div>
			<div class="title"><a href="https://arxiv.org/abs/1908.01977"> Semi-supervised Skin Detection by Network
					with Mutual Guidance</a></div>
			<div class="authors">
				Yi He*, Jiayuan Shi*, Chuan Wang, <strong> Haibin Huang</strong>, Jiaming Liu, Guanbin Li, Risheng Liu,
				Jue Wang
			</div>
			<div class="venue">
				<em> ICCV 2019 </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1908.01977">Project page</a> ] [ <a
					href="https://arxiv.org/abs/1908.01977"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->








		<!--  cvpr workshop -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1904.12945"><img
						src="./publications/raw_denoise/raw_denoise.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/1904.12945"> Learning Raw Image Denoising with Bayer
					Pattern Unification and Bayer Preserving Augmentation </a></div>
			<div class="authors">
				Jiaming Liu, Chi-Hao Wu, Yuzhi Wang, Qin Xu, Yuqian Zhou,<strong> Haibin Huang</strong>, Chuan Wang,
				Shaofan Cai,
				Yifan
				Ding, Haoqiang Fan, Jue Wang
			</div>
			<div class="venue">
				<em> CVPRW(NTIRE 2019)</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1904.12945">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1904.12945.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->




		<!--  Arxiv -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1901.02840"><img
						src="./publications/gif2video/gif2video.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/1901.02840"> GIF2Video: Color Dequantization and
					Temporal
					Interpolation of GIF images </a></div>
			<div class="authors">
				Yang Wang, <strong> Haibin Huang</strong>, Chuan Wang, Tong He, Jue Wang, Minh Hoai
			</div>
			<div class="venue">
				<em> CVPR 2019</em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1901.02840">Project page</a> ] [ <a
					href="https://arxiv.org/abs/1901.02840.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->



		<!--  Arxiv -->
		<div class="publication">
			<div class="thumb"><a href="https://arxiv.org/abs/1901.00680"><img
						src="./publications/geonet/geonet.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://arxiv.org/abs/1901.00680"> GeoNet: Deep Geodesic Networks for Point
					Cloud Analysis </a></div>
			<div class="authors">
				Tong He, <strong> Haibin Huang</strong>, Li Yi, Yuqian Zhou, Chihao Wu, Jue Wang, Stefano Soatto
			</div>
			<div class="venue">
				<em> CVPR 2019 (Oral presentation) </em>
			</div>
			<div class="cite">
				[ <a href="https://arxiv.org/abs/1901.00680">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1901.00680.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->



		<!-- project AAAI 2019 -->
		<div class="publication">
			<div class="thumb"><a href="http://wangchuan.github.io/archive/research/videoinp/"><img
						src="./publications/videoinpainting/video_inpainting.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://wangchuan.github.io/archive/research/videoinp/"> Video Inpainting by
					Jointly Learning Temporal Structure and Spatial Details</a></div>
			<div class="authors">
				Chuan Wang, <strong> Haibin Huang</strong>, Xiaoguang Han, Jue Wang
			</div>
			<div class="venue">
				<em> AAAI 2019</em>
			</div>
			<div class="cite">
				[ <a href="http://wangchuan.github.io/archive/research/videoinp/">Project page</a> ] [ <a
					href="https://arxiv.org/pdf/1806.08482.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!-- project SIGA 2018 
		<div class="publication">
			<div class="thumb"><a href="https://dl.acm.org/citation.cfm?id=3283260"><img src="./publications/gpd/2018_gp_thumbnail.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://dl.acm.org/citation.cfm?id=3283260">	Gourmet Photography Dataset for Food Image Aesthetic Assessment </a></div> 
			<div class="authors">
				Kekai Sheng, Weiming Dong, <strong> Haibin Huang</strong>, Chongyang Ma, Bao-Gang Hu
			</div>
			<div class="venue">
			<em> SIGGRAPH Asia 2018 Technical Briefs  </em>
			</div>
			<div class="cite">
			[ <a href="https://dl.acm.org/citation.cfm?id=3283260"> Publisher page </a>][ <a href="http://chongyangma.com/publications/gp/2018_gp_paper.pdf">Paper </a> ] 
			</div>
			<br>
		</div>
	 End of project -->


		<!-- project SIGA 2018 -->
		<div class="publication">
			<div class="thumb"><a href="https://github.com/ericyi/articulated-part-induction"><img
						src="./publications/deep_part/deep_part.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://github.com/ericyi/articulated-part-induction"> Deep Part Induction
					from
					Articulated Object Pairs </a></div>
			<div class="authors">
				Li Yi, <strong> Haibin Huang</strong>, Difan Liu, Evangelos Kalogerakis, Hao Su, Leonidas Guibas
			</div>
			<div class="venue">
				<em> SIGGRAPH Asia 2018</em>
			</div>
			<div class="cite">
				[ <a href="https://github.com/ericyi/articulated-part-induction"> Project (Code) </a>][ <a
					href="https://arxiv.org/pdf/1809.07417.pdf">Paper </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!-- project SIGA 2018 -->
		<div class="publication">
			<div class="thumb"><a href="http://vcc.szu.edu.cn/research/2018/G2L"><img
						src="./publications/g2l/g2l.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://vcc.szu.edu.cn/research/2018/G2L"> Global-to-Local Generative Model
					for
					3D Shapes </a></div>
			<div class="authors">
				Hao Wang*, Nadav Schor*, Ruizhen Hu, <strong> Haibin Huang</strong>, Daniel Cohen-Or, Hui Huang
			</div>
			<div class="venue">
				<em> SIGGRAPH Asia 2018</em>
			</div>
			<div class="cite">
				[ <a href="http://vcc.szu.edu.cn/research/2018/G2L">Project page</a> ] [ <a
					href="http://vcc.szu.edu.cn/file/upload_file/image/research/att201809231254/G2L.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!-- project cvpr 2017  -->
		<div class="publication">
			<div class="thumb"><a href="http://people.cs.umass.edu/~hbhuang/local_mvcnn/index.html"><img
						src="./publications/local_mvcnn/mvcnn_feature.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://people.cs.umass.edu/~hbhuang/local_mvcnn/index.html">Learning Local
					Shape
					Descriptors from Part Correspondences With Multi-view Convolutional Networks</a></div>
			<div class="authors">
				<strong> Haibin Huang</strong>, Evangelos Kalogerakis, Siddhartha Chaudhuri, Duygu Ceylan, Vladimir Kim,
				Ersin Yumer
			</div>
			<div class="venue">
				<em>TOG 2018. (also presented at SIGGRAPH 2018) </em>
			</div>
			<div class="cite">
				[ <a href="http://people.cs.umass.edu/~hbhuang/local_mvcnn/index.html">Project page</a> ] [ <a
					href="https://arxiv.org/abs/1706.04496"> Paper </a>] [ <a
					href="http://people.cs.umass.edu/~hbhuang/local_mvcnn/index.html"> Code </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->






		<!-- project asia 2017 -->
		<div class="publication">
			<div class="thumb"><a href="http://people.cs.umass.edu/~zlun/papers/PatternGrouping/"><img
						src="./publications/learning_patterns/learning_patter.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://people.cs.umass.edu/~zlun/papers/PatternGrouping/"> Learning to Group
					Discrete Graphical Patterns</a></div>
			<div class="authors">
				Zhaoliang Lun*, Changqing Zou*, <strong> Haibin Huang</strong>, Evangelos Kalogerakis, Ping Tan,
				Marie-Paule Cani, Hao
				Zhang
			</div>
			<div class="venue">
				<em> SIGGRAPH Asia 2017</em>
			</div>
			<div class="cite">
				[ <a href="http://people.cs.umass.edu/~zlun/papers/PatternGrouping/">Project page</a> ] [ <a
					href="http://people.cs.umass.edu/~zlun/papers/PatternGrouping/PatternGrouping.pdf"> Paper </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!--project iccv 2017 -->
		<div class="publication">
			<div class="thumb"><a href="http://i.cs.hku.hk/~xghan/Projects/shapecomp.htm"><img
						src="./publications/iccv_highRes/high_resolution.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://i.cs.hku.hk/~xghan/Projects/shapecomp.htm">High Resolution Shape
					Completion Using Deep Neural Networks for Global Structure and Local Geometry Inference </a>
			</div>
			<div class="authors">
				Xiaoguang Han*, Zhen Li*, <strong> Haibin Huang</strong>, Evangelos Kalogerakis, Yizhou Yu
			</div>
			<div class="venue">
				<em>ICCV 2017. (Spotlight presentation) </em>
			</div>
			<div class="cite">
				[ <a href="http://i.cs.hku.hk/~xghan/Projects/shapecomp.htm">Project page</a> ] [ <a
					href="https://people.cs.umass.edu/~kalo/papers/ShapePatchNet/shape_patchnet_iccv.pdf">
					Paper </a>] [
				<a href="http://i.cs.hku.hk/~xghan/Projects/shapecomp.htm"> Code </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->


		<!-- project CVPR 2017  -->
		<div class="publication">
			<div class="thumb"><a href="https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil"><img
						src="./publications/3dvae/3dvae.jpg"></a>&nbsp;</div>
			<div class="title"><a href="https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil">Synthesizing 3D
					Shapes via Modeling Multi-View Depth Maps and Silhouettes with Deep Generative Networks</a>
			</div>
			<div class="authors">
				Amir Arsalan Soltani, <strong> Haibin Huang</strong>, Jiajun Wu, Tejas Kulkarni, Joshua Tenenbaum
			</div>
			<div class="venue">
				<em>CVPR 2017 </em>
			</div>
			<div class="cite">
				[ <a href="https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil">Project page</a> ] [ <a
					href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Soltani_Synthesizing_3D_Shapes_CVPR_2017_paper.pdf">
					Paper </a>] [ <a href="https://github.com/Amir-Arsalan/Synthesize3DviaDepthOrSil"> Code </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->



		<!-- project TVCG 2017  -->
		<div class="publication">
			<div class="thumb"><a href="http://people.cs.umass.edu/~hbhuang/publications/srpm/index.html"><img
						src="./publications/srpm/srpm_thumbnail.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://people.cs.umass.edu/~hbhuang/publications/srpm/index.html">Shape
					Synthesis from Sketches via Procedural Models and Convolutional Networks</a></div>
			<div class="authors">
				<strong> Haibin Huang</strong>, Evangelos Kalogerakis, M. Ersin Yumer , Radomir Mech
			</div>
			<div class="venue">
				<em> TVCG 2017</em>
			</div>
			<div class="cite">
				[ <a href="http://people.cs.umass.edu/~hbhuang/publications/srpm/index.html">Project page</a> ] [ <a
					href="https://people.cs.umass.edu/~kalo/papers/shapepmconvnet/shapepmconvnet.pdf"> Paper </a>] [
				<a href="http://people.cs.umass.edu/~hbhuang/publications/srpm/index.html"> Code </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!-- project  SGP 2015 -->
		<div class="publication">
			<div class="thumb"><a href="http://people.cs.umass.edu/~hbhuang/publications/bsm/index.html"><img
						src="./publications/bsm/bsm_thumbnail.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://people.cs.umass.edu/~hbhuang/publications/bsm/index.html">Analysis
					and
					synthesis of 3D shape families via deep-learned generative models of surfaces</a></div>
			<div class="authors">
				<strong> Haibin Huang</strong>, Evangelos Kalogerakis, Benjamin Marlin
			</div>
			<div class="venue">
				<em> Computer Graphics Forum (SGP 2015) </em>
			</div>
			<div class="cite">
				[<a href="http://people.cs.umass.edu/~hbhuang/publications/bsm/index.html">Project page</a> ] [ <a
					href="http://people.cs.umass.edu/~hbhuang/publications/bsm/bsm.pdf">Paper </a> 7MB ] [ <a
					href="http://people.cs.umass.edu/~hbhuang/publications/bsm/SourceCode.7z"> Code </a> ] [ <a
					href="http://people.cs.umass.edu/~hbhuang/publications/bsm/bsm_slides.pdf"> Slides </a> <a
					href="http://people.cs.umass.edu/~hbhuang/publications/bsm/presentation.7z"> Video </a> ]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!-- project  EG 2014 -->
		<div class="publication">
			<div class="thumb"><a href="http://www.chongyangma.com/publications/st/index.html"><img
						src="./publications/st/2014_st_thumbnai.png"></a>&nbsp;</div>
			<div class="title"><a href="http://www.chongyangma.com/publications/st/index.html">Analogy-Driven 3D
					Style
					Transfer</a></div>
			<div class="authors">
				Chongyang Ma, <strong> Haibin Huang</strong>, Alla Sheffer, Evangelos Kalogerakis, Rui Wang
			</div>
			<div class="venue">
				<em> Computer Graphics Forum (Eurographics 2014)</em>
			</div>
			<div class="cite">
				[<a href="http://www.chongyangma.com/publications/st/index.html">Project page</a> ] [ <a
					href="http://www.chongyangma.com/publications/st/2014_st_preprint.pdf">Paper </a> 17MB ] [ <a
					href="publications/st/2014_st_video.mp4">Video</a> 28MB <a
					href="https://www.youtube.com/watch?v=h0xF6R5MpyA" target="_blank">Youtube</a> ] [ <a
					href="http://www.chongyangma.com/publications/st/2014_st_slides.pdf">Slides</a> 8MB ]
			</div>
			<br>
		</div>
		<!-- End of project -->

		<!-- project  SIG 2012 -->
		<div class="publication">
			<div class="thumb"><a href="http://people.cs.umass.edu/~hbhuang/"><img
						src="./publications/gns/2012_gns_thumbnai.jpg"></a>&nbsp;</div>
			<div class="title"><a href="http://people.cs.umass.edu/~hbhuang/">Point Sampling with General Noise
					Spectrum</a></div>
			<div class="authors">
				Yahan Zhou, <strong> Haibin Huang</strong>, Li-Yi Wei, Rui Wang
			</div>
			<div class="venue">
				<em> SIGGRAPH 2012 </em>
			</div>
			<div class="cite">
				[<a href="http://graphics.cs.umass.edu/pubs/sig12_gns.pdf"> paper (27M) </a> ] [ <a
					href="http://graphics.cs.umass.edu/pubs/sig12_gns_small.pdf"> paper (11M) </a>] [ <a
					href="http://graphics.cs.umass.edu/pubs/sig12_gns_supp.pdf"> Supp</a> ] [ <a
					href="http://graphics.cs.umass.edu/pubs/gsn_gpu.zip"> source Code </a>]
			</div>
			<br>
		</div>
		<!-- End of project -->
	</div>



	<div class="container section-anchor" id="Thesis">
		<h2>Thesis</h2>
		<!-- project asia 2017 -->
		<div class="publication">
			<div class="thumb"><a
					href="http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=2156&context=dissertations_2"><img
						src="./images/umass_logo.jpg"></a>&nbsp;</div>
			<div class="title"><a
					href="http://scholarworks.umass.edu/cgi/viewcontent.cgi?article=2156&context=dissertations_2">
					Deep-learned Generative Representations of 3D Shape Families </a></div>
			<div class="authors">
				Haibin Huang
			</div>
			<div class="venue">
				<em>Umass Amherst, August 2017</em>
			</div>
			<br>
		</div>
		<!-- End of project -->
	</div>


	<div class="container section-anchor" id="Professional">
		<h2>Professional Activities</h2>
		<h3>Journal editorial board</h3>
		<li>The Visual Computer Associate Editor 2022--present </li>
		<h3>Program committee</h3>
		<li>SIGGRAPH Technical Papers Committee 2025</li>
		<li>SIGGRAPH Asia Technical Communications and Posters 2024</li>
		<li> Eurographics Short Papers 2024</li>
		<li>Computational Visual Media (CVM) 2023 - 2025</li>
		<li>Shape Modeling International (SMI) 2020 - 2025</li>
		<h3>Paper reviewer</h3>
		<li>Transactions on Graphics</li>
		<li>Transactions on Pattern Analysis and Machine Intelligence</li>
		<li>SIGGRAPH </li>
		<li>SIGGRAPH ASIA </li>
		<li>ACM Symposium on User Interface Software and Technology (UIST) </li>
		<li>Neural Information Processing Systems (NeurIPS) </li>
		<li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) </li>
		<li>IEEE International Conference on Computer Vision (ICCV) </li>
		<li>European Conference on Computer Vision (ECCV) </li>
		<li>Eurographics </li>
		<li>Pacific Graphics</li>
		<li>Computer Graphics Forum</li>
		<li>AAAI Conference on Artificial Intelligence (AAAI)</li>
		<li>Uncertainty in Artificial Intelligence (UAI)</li>
		<!-- <h2>Misc</h2>	
		<p><h3>Here is a <a href=http://www.wordle.net/>wordle</a> of my research.</h3></p>
         <img width=100% src="./images/wordle.png" > -->
	</div>

	<!-- Bootstrap core JavaScript
 ================================================== -->
	<!-- Placed at the end of the document so the pages load faster -->
	<script src="./style_files/jquery.min.js.download"></script>
	<script src="./style_files/bootstrap.min.js.download"></script>

</body>
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-74517202-2"></script>
<script>
	window.dataLayer = window.dataLayer || [];
	function gtag() { dataLayer.push(arguments); }
	gtag('js', new Date());
	gtag('config', 'UA-74517202-2');
</script>

</html>